
<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Charlotte Caucheteux</title>

  <meta name="author" content="Charlotte Caucheteux">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:67%;vertical-align:middle">
              <p style="text-align:center">
                <name>Charlotte Caucheteux</name>
              </p>
              <p>&nbsp
              </p>
              <p>
              </p>
              <p> <font size=3px> I am a PhD. student at Meta AI (prev. Facebook AI Research) and Inria Saclay,
                advised by <a href="https://kingjr.github.io/" target="_blank"> <b> <font size=3px> Jean-Remi King </font></b> </a>
                and <a href="https://alexandre.gramfort.net/" target="_blank"> <b> <font size=3px>  Alexandre Gramfort </font></b> </a>.
                I work on language processing in deep neural networks and the human brain. </font>
                     <!-- I am deeply interested in the computational bases of natural and artificial intelligence, AI for healthcare and biology.  -->
 
                <br>
                <br>
                <font size=3px> Prior to my PhD., I graduated from Ecole Polytechnique and had several exepriences in AI for Healthcare: 
                  as a data scientist at <a href="https://owkin.com/" target="_blank"> <b> <font size=3px>  Owkin </font></b>  </a> 
                  and at the French Hospitals 
                  <a href="https://www.aphp.fr/AP-HP " target="_blank"> <b> <font size=3px>  AP-HP </font></b>, </a> 
                 where I worked on a patient monitoring app during the COVID pandemic. 
                  In 2019, two teammates and I founded a collective of AI-generated artworks, <a href="https://noartist.fr/" target="_blank"> <b> <font size=3px>  NoArtist </font></b> </a>. 
                <br>
                <br>
                <font size=3px> My research interests include deep learning, neuroscience, natural language processing, AI for healthcare & biology. 
                <!-- <font size=3px> I am interested about the computational bases of natural and artificial intelligence, AI for Healthcare and Biology.  -->
                      
                <br>
                <br>
                <font size=3px>Feel free to connect on <a href="https://www.linkedin.com/in/ccaucheteux/" target="_blank"> <font size=3px>  LinkedIn </font> </a> or <a href="https://twitter.com/c_caucheteux" target="_blank"  > <font size=3px> Twitter  </font></a>. </li><p></p>
                <!-- Email: charlotte.caucheteux@gmail.com </font> -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/photo.jpg" class="hoverZoomLink">
            </td>
          </tr>
<!-- 
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>PhD. project</heading>
              <p>
                <font size=3px> My research lies on the intersection of deep learning, neuroscience and natural language processing. 
                  <br>
                  In short, I study language representations in deep neural networks and the human brain. 
                  I mostly focus on transformer-based language models and neuro-imaging techniques (fMRI, MEG, EEG). 
                  
                  <br>
                  <!-- During my PhD. I have mostly focused on transformer-based models (e.g. GPT-2, BERT) and neuro-imaging techniques (fMRI, MEG & EEG).  -->
                  <!-- Some questions I am interested in:
                  <ul>
                  <li>What are the neural and computational bases of language?</li>
                  <li>Can we decode language from non-invasive neuro-imaging data (MEG/EEG/fMRI)?</li>
                  <li>Can we leverage deep learning to extract relevant representations of noisy brain signals?</li>
                  </ul> -->
                  <!-- To explore these questions, I develop and analyse deep learning algorithms and analyse . -->
                <!-- </font>
              </p>
            </td>
          </tr>
        </tbody></table> -->


        <table style="width:110%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:110%;vertical-align:middle">
              <heading>Selected Publications</heading>
              <br>
              <br>
              <font size=3px> I am interested in the computational basis of natural and artificial intelligence, 
                with a focus on language. 
                As part of my PhD., I have been investigating language representations in deep neural networks and the human brain, 
                using transformer-based models and neuroimaging techniques (fMRI, MEG, and EEG). 
                My full publication history can be found on <a href="https://scholar.google.com/citations?user=qu7KObMAAAAJ&hl=fr" target="_blank"> <b> <font size=3px> Google Scholar </font> </b> </a>.
                
                
                
                <!-- I am interested in the computational basis of natural and artificial intelligence, with a focus on language. 
              As part of my PhD., I have been studying language representations in deep neural networks and the human brain, 
              with a focus on transformer-based models and neuroimaging techniques (fMRI, MEG, EEG). -->
            </font>
            <br>
              <p>
                <!-- <br>
                <br> -->
              <subheading>  <font size=3px> Journal Articles </font></subheading>
              <p>
                <ul>

                  <li><a href="https://www.nature.com/articles/s42003-022-03036-1" target="_blank"> <b> Brains and algorithms partially converge in natural language processing </b> </a>  <br> <b>Charlotte Caucheteux </b>, Jean-Remi King. <font style="color:RGB(30,0,80);"> 
                    <br> <b> Nature Communications Biology</b>, 2022</font> </li> <p></p>

                  <!-- <blockquote class="twitter-tweet"><p lang="en" dir="ltr">üéâPaper out: ‚ÄòBrains and algorithms partially converge in natural language processing‚Äô<br> <br>by <a href="https://twitter.com/c_caucheteux?ref_src=twsrc%5Etfw">@c_caucheteux</a>, and now freely available at Nature <a href="https://twitter.com/CommsBio?ref_src=twsrc%5Etfw">@CommsBio</a>:<a href="https://t.co/MpenOUaKwS">https://t.co/MpenOUaKwS</a><br> <br>The summary thread below üëá <a href="https://t.co/gMruZgGIOv">pic.twitter.com/gMruZgGIOv</a></p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1496425017474695169?ref_src=twsrc%5Etfw">February 23, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> -->

                  <li><a href="https://www.nature.com/articles/s41598-022-20460-9" target="_blank"> <b> Deep language algorithms predict semantic comprehension from brain activity </b> <br> </a> <b>Charlotte Caucheteux</b>, Alexandre Gramfort, Jean-Remi King.  <br> <font style="color:RGB(30,0,80);"> <b> Nature Scientific Reports </b>, 2022</font> </li> <p></p>

                  <!-- <blockquote class="twitter-tweet"><p lang="en" dir="ltr">ü§ñüß† Our latest paper is now out:<a href="https://t.co/NZNea2VZ4U">https://t.co/NZNea2VZ4U</a><br><br>‚ÄúDeep language algorithms predict semantic comprehension from brain activity‚Äù, by <a href="https://twitter.com/c_caucheteux?ref_src=twsrc%5Etfw">@c_caucheteux</a>, <a href="https://twitter.com/agramfort?ref_src=twsrc%5Etfw">@agramfort</a> &amp; <a href="https://twitter.com/JeanRemiKing?ref_src=twsrc%5Etfw">@JeanRemiKing</a><br> <br>The summary thread below belowüëá<br><br>1/n <a href="https://t.co/CJfBdeDlY3">pic.twitter.com/CJfBdeDlY3</a></p>&mdash; Charlotte Caucheteux (@c_caucheteux) <a href="https://twitter.com/c_caucheteux/status/1579842525719732229?ref_src=twsrc%5Etfw">October 11, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> -->

                  <li><a href="https://arxiv.org/abs/2111.14232?context=q-bio" target="_blank"> <b> Long-range and hierarchical language predictions in brains and algorithms </b> </a> <br> <b>Charlotte Caucheteux</b>, Alexandre Gramfort, Jean-Remi King.  <br> <font style="color:RGB(30,0,80);">  In prep. for <b> Nature Human Behaviour</b>, 2022</font> </li> <p></p>

                  <li><a href="https://arxiv.org/abs/2208.12266" target="_blank"> <b> Decoding speech from non-invasive brain recordings </b> <br> </a> Alexandre Defossez, <b>Charlotte Caucheteux</b>, Jeremy Rapin, Ori Kabeli, Jean-Remi King.  <br> <font style="color:RGB(30,0,80);">  Under Review, 2022</font> </li> <p></p>                                  
                  <li><a href="https://www.nature.com/articles/s41598-021-99991-6" target="_blank"> <b> Predictive usefulness of RT-PCR testing in different patterns of Covid-19 symptomatology: analysis of a French cohort of 12,810 outpatients. </b> <br> </a> Caroline Apra*, <b>Charlotte Caucheteux*</b>, Arthur Mensch* et al.  <br> <font style="color:RGB(30,0,80);">  <b>Nature Scientific Reports</b>, 2021 </font> </li> <p></p>             

                </ul>
                </p>

                <subheading>  <font size=3px> Conference Articles </font></subheading>
                <p>
                  <ul>


                  <li><a href="https://aclanthology.org/2021.findings-emnlp.308/" target="_blank"> <b> Model-based analysis of brain activity reveals the hierarchy of language in 305 subjects </b> <br> </a> <b>Charlotte Caucheteux</b>, Alexandre Gramfort, Jean-Remi King.  <br> 
                    <font style="color:RGB(30,0,80);"> Findings of <b> EMLNP </b>, 2021 </font> </li> <p></p>
                    <!-- <font style="color:RGB(30,0,80);"> Findings of the Conference on Empirical Methods in Natural Language Processing <b> (EMLNP) </b>, 2021 </font> </li> <p></p> -->

                  <!-- <blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;Model-based analysis of brain activity reveals the hierarchy of language&quot;<br><br>Our EMNLP paper by <a href="https://twitter.com/c_caucheteux?ref_src=twsrc%5Etfw">@c_caucheteux</a> <a href="https://twitter.com/agramfort?ref_src=twsrc%5Etfw">@agramfort</a> &amp; myself is out: <a href="https://t.co/BxvrbZNkPt">https://t.co/BxvrbZNkPt</a><br><br>It shows (w/ emoji-based equations!) how deepnets can efficiently recover the language hierarchy in the<br><br>Summaryüëá<br>1/7 <a href="https://t.co/3QOcTfsivu">pic.twitter.com/3QOcTfsivu</a></p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1447909791435825159?ref_src=twsrc%5Etfw">October 12, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> -->

                  <li><a href="https://proceedings.mlr.press/v139/caucheteux21a.html" target="_blank"> <b> Disentangling syntax and semantics in the brain with deep networks </b> </a> <br> <b>Charlotte Caucheteux</b>, Alexandre Gramfort, Jean-Remi King.  <br> 
                    <font style="color:RGB(30,0,80);"><b>ICML</b>, 2021</font> </li> <p></p>
                    <!-- <font style="color:RGB(30,0,80);">International Conference on Machine Learning <b>(ICML)</b>, 2021</font> </li> <p></p> -->

                  <!-- <blockquote class="twitter-tweet"><p lang="en" dir="ltr">Our new <a href="https://twitter.com/hashtag/ICML2021?src=hash&amp;ref_src=twsrc%5Etfw">#ICML2021</a> paper is out !<br><br>We align brain and GPT-2 activations to decompose the brain activity of 345 subjects into syntactic, semantic, lexical and compositional components. <br><br>Paper: <a href="https://t.co/fBbTHFSiAf">https://t.co/fBbTHFSiAf</a><br>Spotlight: <a href="https://t.co/hWOapyc2r5">https://t.co/hWOapyc2r5</a><br>Poster: Fri. 9am-11am CET <a href="https://t.co/17MwLP1K3j">https://t.co/17MwLP1K3j</a></p>&mdash; Charlotte Caucheteux (@c_caucheteux) <a href="https://twitter.com/c_caucheteux/status/1418305962662895621?ref_src=twsrc%5Etfw">July 22, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> -->

                  <li><a href="https://arxiv.org/abs/2206.01685" target="_blank"> <b> Toward a realistic model of speech processing in the brain with self-supervised learning </b> <br> </a> Juliette Millet*, <b>Charlotte Caucheteux*</b>, P. Orhan, Y. Boubenec, A. Gramfort, E. Dunbar, C. Pallier, J.R. King.  <br>
                    <font style="color:RGB(30,0,80);">   <b> NeurIPS </b>, 2022</font> </li> <p></p>
                    <!-- <font style="color:RGB(30,0,80);">  Neural Information Processing Systems <b> (NeurIPS) </b>, 2022</font> </li> <p></p> -->

                  <!-- <blockquote class="twitter-tweet"><p lang="en" dir="ltr">üî•Preprint out: <br><br>`Toward a realistic model of speech processing in the brain with self-supervised learning‚Äô:<a href="https://t.co/rJH6t6H6sm">https://t.co/rJH6t6H6sm</a><br><br>by J. Millet*, <a href="https://twitter.com/c_caucheteux?ref_src=twsrc%5Etfw">@c_caucheteux</a>* and our wonderful team:<br><br>The 3 main results summarized below üëá <a href="https://t.co/mdrJpbrb3M">pic.twitter.com/mdrJpbrb3M</a></p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1533720262344073218?ref_src=twsrc%5Etfw">June 6, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> -->


                  <!-- <blockquote class="twitter-tweet"><p lang="en" dir="ltr">Modern language algorithms are getting great but still remain far from humans.<br><br>To explain this gap, we hypothesize that the üß†, unlike these algorithms, is not tuned to predict adjacent words (i.e. a shorted-sighted goal) but rather makes long-range and hierarchical predictions. <a href="https://t.co/gujDxbMExl">pic.twitter.com/gujDxbMExl</a></p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1465716359246094342?ref_src=twsrc%5Etfw">November 30, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> -->

              


                    <!-- Efficient Sample Collection Strategy for Reinforcement Learning </b> </a> <br> <b>Jean Tarbouriech</b>, Matteo Pirotta, Michal Valko, Alessandro Lazaric <br> <font style="color:RGB(30,0,80);">Neural Information Processing Systems <b>(NeurIPS)</b>, 2021  &nbsp [spotlight - 3% acceptance rate] </font> </li> <p></p>
                  <li><a href="https://papers.nips.cc/paper/2021/file/367147f1755502d9bc6189f8e2c3005d-Supplemental.pdf" target="_blank"> <b> Stochastic Shortest Path: Minimax, Parameter-Free and Towards Horizon-Free Regret </b> </a> <br> <b>Jean Tarbouriech</b>*, Runlong Zhou*, Simon S. Du, Matteo Pirotta, Michal Valko, Alessandro Lazaric <br> <font style="color:RGB(30,0,80);">Neural Information Processing Systems <b>(NeurIPS)</b>, 2021 &nbsp [spotlight - 3% acceptance rate]</font> </li> <p></p>
                        <li><a href="http://proceedings.mlr.press/v132/tarbouriech21a/tarbouriech21a.pdf" target="_blank"> <b> Sample Complexity Bounds for Stochastic Shortest Path with a Generative Model </b> </a> <br> <b>Jean Tarbouriech</b>, Matteo Pirotta, Michal Valko, Alessandro Lazaric <br>  <font style="color:RGB(30,0,80);">Algorithmic Learning Theory <b>(ALT)</b>, 2021</font> </li> <p></p>
                        <li> <a href="https://papers.nips.cc/paper/2020/file/81e793dc8317a3dbc3534ed3f242c418-Supplemental.pdf" target="_blank"  > <b> Improved Sample Complexity for Incremental Autonomous Exploration in MDPs </b> </a> <br> <b>Jean Tarbouriech</b>, Matteo Pirotta, Michal Valko, Alessandro Lazaric <br><font style="color:RGB(30,0,80);">Neural Information Processing Systems <b>(NeurIPS)</b>, 2020 &nbsp [oral - 1% acceptance rate]</font> </li> <p></p>
                            <li> <a href="https://papers.nips.cc/paper/2020/file/a554f89dd61cabd2ff833d3468e2008a-Supplemental.pdf" target="_blank"  > <b> Adversarial Attacks on Linear Contextual Bandits </b> </a> <br> Evrard Garcelon, Baptiste Roziere, Laurent Meunier, <b> Jean Tarbouriech</b>, Olivier Teytaud, Alessandro Lazaric, Matteo Pirotta <br> <font style="color:RGB(30,0,80);">Neural Information Processing Systems <b>(NeurIPS)</b>, 2020</font> </li> <p></p>
                            <li> <a href="http://proceedings.mlr.press/v119/tarbouriech20a/tarbouriech20a-supp.pdf" target="_blank"  > <b> No-Regret Exploration in Goal-Oriented Reinforcement Learning </b> </a> <br> <b>Jean Tarbouriech</b>, Evrard Garcelon, Michal Valko, Matteo Pirotta, Alessandro Lazaric  <br> <font style="color:RGB(30,0,80);">International Conference on Machine Learning <b>(ICML)</b>, 2020</font> </li> <p></p>
                            <li> <a href="http://proceedings.mlr.press/v124/tarbouriech20a/tarbouriech20a-supp.pdf" target="_blank"  > <b> Active Model Estimation in Markov Decision Processes </b> </a> <br>  <b>Jean Tarbouriech</b>, Shubhanshu Shekhar, Matteo Pirotta, Mohammad Ghavamzadeh, Alessandro Lazaric <br> <font style="color:RGB(30,0,80);">Uncertainty in Artificial Intelligence <b>(UAI)</b>, 2020</font>  </li><p></p>
                            <li> <a href="http://proceedings.mlr.press/v89/tarbouriech19a/tarbouriech19a.pdf" target="_blank"  > <b> Active Exploration in Markov Decision Processes </b> </a> <br>  <b>Jean Tarbouriech</b>, Alessandro Lazaric <br> <font style="color:RGB(30,0,80);">International Conference on Artificial Intelligence and Statistics <b>(AISTATS)</b>, 2019</font> </li><p></p> --> 
              </ul>
              </p>
                <ul>
 </li>
                </ul>
            </td>
          </tr>
        </tbody></table>

        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
        <heading> Selected Threads</heading>
        <p>
          <ul>

        </ul>
        </p>
      </td>
    </tr>
  </tbody></table> -->

  <table style="width:110%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
    <td style="padding:20px;width:110%;vertical-align:middle">
      <heading>Selected Threads  </heading>
      <br>
      <br>

      <blockquote class="twitter-tweet"><p lang="en" dir="ltr">üî•Our work has now been accepted to NeurIPS 2022 !! <br><br>`Toward a realistic model of speech processing in the brain with self-supervised learning‚Äô:<a href="https://t.co/weiGlaiD65">https://t.co/weiGlaiD65</a><br><br>Let‚Äôs meet in New Orleans on Tue 29 Nov 2:30pm PST (Hall J #524). <br><br>A recap of the 3 main results below üëá <a href="https://t.co/ng7w8luStr">pic.twitter.com/ng7w8luStr</a></p>&mdash; Charlotte Caucheteux @NeurIPS (@c_caucheteux) <a href="https://twitter.com/c_caucheteux/status/1592895883393499136?ref_src=twsrc%5Etfw">November 16, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

      <blockquote class="twitter-tweet"><p lang="en" dir="ltr">ü§ñüß† Our latest paper is now out:<a href="https://t.co/NZNea2VZ4U">https://t.co/NZNea2VZ4U</a><br><br>‚ÄúDeep language algorithms predict semantic comprehension from brain activity‚Äù, by <a href="https://twitter.com/c_caucheteux?ref_src=twsrc%5Etfw">@c_caucheteux</a>, <a href="https://twitter.com/agramfort?ref_src=twsrc%5Etfw">@agramfort</a> &amp; <a href="https://twitter.com/JeanRemiKing?ref_src=twsrc%5Etfw">@JeanRemiKing</a><br> <br>The summary thread below belowüëá<br><br>1/n <a href="https://t.co/CJfBdeDlY3">pic.twitter.com/CJfBdeDlY3</a></p>&mdash; Charlotte Caucheteux (@c_caucheteux) <a href="https://twitter.com/c_caucheteux/status/1579842525719732229?ref_src=twsrc%5Etfw">October 11, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

      <blockquote class="twitter-tweet"><p lang="en" dir="ltr">Our new <a href="https://twitter.com/hashtag/ICML2021?src=hash&amp;ref_src=twsrc%5Etfw">#ICML2021</a> paper is out !<br><br>We align brain and GPT-2 activations to decompose the brain activity of 345 subjects into syntactic, semantic, lexical and compositional components. <br><br>Paper: <a href="https://t.co/fBbTHFSiAf">https://t.co/fBbTHFSiAf</a><br>Spotlight: <a href="https://t.co/hWOapyc2r5">https://t.co/hWOapyc2r5</a><br>Poster: Fri. 9am-11am CET <a href="https://t.co/17MwLP1K3j">https://t.co/17MwLP1K3j</a></p>&mdash; Charlotte Caucheteux (@c_caucheteux) <a href="https://twitter.com/c_caucheteux/status/1418305962662895621?ref_src=twsrc%5Etfw">July 22, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

      <blockquote class="twitter-tweet"><p lang="en" dir="ltr">üéâPaper out: ‚ÄòBrains and algorithms partially converge in natural language processing‚Äô<br> <br>by <a href="https://twitter.com/c_caucheteux?ref_src=twsrc%5Etfw">@c_caucheteux</a>, and now freely available at Nature <a href="https://twitter.com/CommsBio?ref_src=twsrc%5Etfw">@CommsBio</a>:<a href="https://t.co/MpenOUaKwS">https://t.co/MpenOUaKwS</a><br> <br>The summary thread below üëá <a href="https://t.co/gMruZgGIOv">pic.twitter.com/gMruZgGIOv</a></p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1496425017474695169?ref_src=twsrc%5Etfw">February 23, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

      <!-- <blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;Model-based analysis of brain activity reveals the hierarchy of language&quot;<br><br>Our EMNLP paper by <a href="https://twitter.com/c_caucheteux?ref_src=twsrc%5Etfw">@c_caucheteux</a> <a href="https://twitter.com/agramfort?ref_src=twsrc%5Etfw">@agramfort</a> &amp; myself is out: <a href="https://t.co/BxvrbZNkPt">https://t.co/BxvrbZNkPt</a><br><br>It shows (w/ emoji-based equations!) how deepnets can efficiently recover the language hierarchy in the<br><br>Summaryüëá<br>1/7 <a href="https://t.co/3QOcTfsivu">pic.twitter.com/3QOcTfsivu</a></p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1447909791435825159?ref_src=twsrc%5Etfw">October 12, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> -->

      <!-- <blockquote class="twitter-tweet"><p lang="en" dir="ltr">Modern language algorithms are getting great but still remain far from humans.<br><br>To explain this gap, we hypothesize that the üß†, unlike these algorithms, is not tuned to predict adjacent words (i.e. a shorted-sighted goal) but rather makes long-range and hierarchical predictions. <a href="https://t.co/gujDxbMExl">pic.twitter.com/gujDxbMExl</a></p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1465716359246094342?ref_src=twsrc%5Etfw">November 30, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> -->
      

      
      <ul>
</li>
        </ul>
    </td>
  </tr>
</tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Misc.</heading>
              <p>
                <ul>

                        <!-- <li> I received an MSc/BSc in Applied Mathematics from √âcole Polytechnique (<i>dipl√¥me d'Ing√©nieur</i>). During my studies, I was a Machine Learning intern at Owkin, BCG Gamma, and .</li><p></p> -->
                        <!-- <li> Outside of work, I enjoy playing soccer ‚öΩ &nbsp scuba diving üê† &nbsp and backpacking üåç   </li><p></p> -->
                        <li> I received an MSc/BSc from Ecole Polytechnique (<i>dipl√¥me d'Ing√©nieur</i>), with a specialisation in Machine Learning.<p></p>
                        <li> I have a strong interest in Healthcare. Prior to my PhD., I had the chance to work for Owkin, a start-up (now unicorn!) applying AI to oncology (2017). I also worked for the Assistance Publique‚ÄìH√¥pitaux de Paris (AP-HP) during the COVID crisis (2019).  </p>
                            <!-- <li> I also enjoy drawing actionable impact. Previous to my PhD., I had the chance to work for Owkin, a start-up using AI for oncology (2017), and for the Assistance Publique‚ÄìH√¥pitaux de Paris (AP-HP) during the COVID crisis (2019).  p></p> -->
                        <li> Finally, I enjoy arts arts üé® and music üéπ. In 2019, two teammates and I founded <a href="https://noartist.fr/" target="_blank"> NoArtist </a>, a collective of AI-generated artworks. We regularly organise exhibitions and events to democratise AI through arts.<p></p>
                        
                </ul>
              </p>
            </td>
          </tr>
        </tbody></table>

        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <font style="color:RGB(200, 200, 200);">Website template from <a href="https://github.com/jonbarron/jonbarron_website" target="_blank"   style="color:RGB(200, 200, 200);">here</a></font>
              </p>
            </td>
          </tr>
        </tbody></table> -->


</body>

</html>
