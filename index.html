
<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Charlotte Caucheteux</title>

  <meta name="author" content="Charlotte Caucheteux">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:67%;vertical-align:middle">
              <p style="text-align:center">
                <name>Charlotte Caucheteux</name>
              </p>
              <p>&nbsp
              </p>
              <p>
              </p>
              <p> <font size=3px> I am a Research Scientist in the <a href="https://llama.meta.com/"  target="_blank"><b><font size=3px>LLaMa</font></b></a> team at <a href="https://ai.meta.com/" target="_blank"><b><font size=3px>Meta</font></b></a> (GenAI), working on fine-tuning Large Language Models. 
                <!-- My recent projects have involved exploring sparse architectures and enhancing large language models with tools and memory. -->

                <br>
                <br>
                My research interests include Large Language Models, Neuroscience, AI for healthcare & biology.

          
                
                <br>
                <br>
                I graduated from Ecole Polytechnique in 2019 and pursed a PhD. in deep learning between 2020 and 2023 at Meta AI
                (<a href="https://ai.facebook.com/research/" target="_blank"><b><font size=3px>FAIR</font></b></a>)
                <!-- Meta AI  -->
                and <a href="https://www.inria.fr/en"  target="_blank"><b><font size=3px>Inria</font></b></a>, focusing on representations in deep language models and the human brain.
                <!-- advised by <a href="https://kingjr.github.io/" target="_blank"> <b> <font size=3px> Jean-Remi King </font></b> </a> -->
                <!-- and <a href="https://alexandre.gramfort.net/" target="_blank"> <b> <font size=3px>  Alexandre Gramfort </font></b> </a>. -->
                <!-- I worked on language processing in deep language models and the human brain. </font> -->
                     <!-- I am deeply interested in the computational bases of natural and artificial intelligence, AI for healthcare and biology.  -->

                <font size=3px> Prior to my PhD, I gained experience in AI for Healthcare 
                  <!-- worked as a data scientist at Owkin and French Hospitals AP-HP, and co-founded an AI-art collective, NoArtist.  -->
                  
                  <!-- My interests include deep learning, neuroscience, natural language processing, and AI for healthcare & biology.  -->
                  
                  <!-- and had several exepriences in AI for Healthcare: -->
                  as a data scientist at <a href="https://owkin.com/" target="_blank"> <b> <font size=3px>  Owkin </font></b>  </a>
                  and at the French Hospitals
                  <a href="https://www.aphp.fr/AP-HP " target="_blank"> <b> <font size=3px>  AP-HP </font></b>, </a>
                 where I contributed to a patient monitoring app during the COVID pandemic.
                  In 2019, I co-founded <a href="https://noartist.fr/" target="_blank"> <b> <font size=3px>  NoArtist</font></b></a>, a collective of AI-generated artworks.
                <!-- <br>
                <br> -->
                <!-- <font size=3px> My research interests include Large Language Models, Neuroscience, AI for healthcare & biology. -->
                <!-- <font size=3px> I am interested about the computational bases of natural and artificial intelligence, AI for Healthcare and Biology.  -->

                <br>
                <br>
                <font size=3px>Feel free to connect on <a href="https://www.linkedin.com/in/ccaucheteux/" target="_blank"> <font size=3px>  LinkedIn </font> </a> or <a href="https://twitter.com/c_caucheteux" target="_blank"  > <font size=3px> Twitter  </font></a>. </li><p></p>
                <!-- Email: charlotte.caucheteux@gmail.com </font> -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/photo.jpg" class="hoverZoomLink">
            </td>
          </tr>
<!--
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>PhD. project</heading>
              <p>
                <font size=3px> My research lies on the intersection of deep learning, neuroscience and natural language processing.
                  <br>
                  In short, I study language representations in deep neural networks and the human brain.
                  I mostly focus on transformer-based language models and neuro-imaging techniques (fMRI, MEG, EEG).

                  <br>
                  <!-- During my PhD. I have mostly focused on transformer-based models (e.g. GPT-2, BERT) and neuro-imaging techniques (fMRI, MEG & EEG).  -->
                  <!-- Some questions I am interested in:
                  <ul>
                  <li>What are the neural and computational bases of language?</li>
                  <li>Can we decode language from non-invasive neuro-imaging data (MEG/EEG/fMRI)?</li>
                  <li>Can we leverage deep learning to extract relevant representations of noisy brain signals?</li>
                  </ul> -->
                  <!-- To explore these questions, I develop and analyse deep learning algorithms and analyse . -->
                <!-- </font>
              </p>
            </td>
          </tr>
        </tbody></table> -->


        <table style="width:110%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:110%;vertical-align:middle">
              <heading>Selected Publications</heading>
              <br>
              <br>
              <font size=3px> I am interested in the computational basis of natural and artificial intelligence,
                with a focus on language.
                As part of my PhD., I have been investigating language representations in deep neural networks and the human brain,
                using transformer-based language models and neuroimaging techniques (fMRI, MEG, and EEG).
                My publication history can be found on <a href="https://scholar.google.com/citations?user=qu7KObMAAAAJ&hl=fr" target="_blank"> <b> <font size=3px> Google Scholar </font> </b> </a>.



                <!-- I am interested in the computational basis of natural and artificial intelligence, with a focus on language.
              As part of my PhD., I have been studying language representations in deep neural networks and the human brain,
              with a focus on transformer-based models and neuroimaging techniques (fMRI, MEG, EEG). -->
            </font>
            <br>
              <p>
                <!-- <br>
                <br> -->
              <subheading>  <font size=3px> Journal Articles </font></subheading>
              <p>
                <ul>

                  <li><a href="https://www.nature.com/articles/s41562-022-01516-2" target="_blank"> <b> Evidence of a predictive coding hierarchy in the human brain listening to speech </b> </a> <br> <b>Charlotte Caucheteux</b>, Alexandre Gramfort, Jean-Remi King.  <br> <font style="color:RGB(30,0,80);"> <b> Nature Human Behaviour</b>, 2023</font> </li> <p></p>


                  <li><a href="https://www.nature.com/articles/s42003-022-03036-1" target="_blank"> <b> Brains and algorithms partially converge in natural language processing </b> </a>  <br> <b>Charlotte Caucheteux </b>, Jean-Remi King. <font style="color:RGB(30,0,80);">
                    <br> <b> Nature Communications Biology</b>, 2022</font> </li> <p></p>

                    <li><a href="https://www.nature.com/articles/s41598-022-20460-9" target="_blank"> <b> Deep language algorithms predict semantic comprehension from brain activity </b> <br> </a> <b>Charlotte Caucheteux</b>, Alexandre Gramfort, Jean-Remi King.  <br> <font style="color:RGB(30,0,80);"> <b> Nature Scientific Reports </b>, 2022</font> </li> <p></p>
                    <!-- <blockquote class="twitter-tweet"><p lang="en" dir="ltr">üéâPaper out: ‚ÄòBrains and algorithms partially converge in natural language processing‚Äô<br> <br>by <a href="https://twitter.com/c_caucheteux?ref_src=twsrc%5Etfw">@c_caucheteux</a>, and now freely available at Nature <a href="https://twitter.com/CommsBio?ref_src=twsrc%5Etfw">@CommsBio</a>:<a href="https://t.co/MpenOUaKwS">https://t.co/MpenOUaKwS</a><br> <br>The summary thread below üëá <a href="https://t.co/gMruZgGIOv">pic.twitter.com/gMruZgGIOv</a></p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1496425017474695169?ref_src=twsrc%5Etfw">February 23, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> -->


                  <!-- <blockquote class="twitter-tweet"><p lang="en" dir="ltr">ü§ñüß† Our latest paper is now out:<a href="https://t.co/NZNea2VZ4U">https://t.co/NZNea2VZ4U</a><br><br>‚ÄúDeep language algorithms predict semantic comprehension from brain activity‚Äù, by <a href="https://twitter.com/c_caucheteux?ref_src=twsrc%5Etfw">@c_caucheteux</a>, <a href="https://twitter.com/agramfort?ref_src=twsrc%5Etfw">@agramfort</a> &amp; <a href="https://twitter.com/JeanRemiKing?ref_src=twsrc%5Etfw">@JeanRemiKing</a><br> <br>The summary thread below belowüëá<br><br>1/n <a href="https://t.co/CJfBdeDlY3">pic.twitter.com/CJfBdeDlY3</a></p>&mdash; Charlotte Caucheteux (@c_caucheteux) <a href="https://twitter.com/c_caucheteux/status/1579842525719732229?ref_src=twsrc%5Etfw">October 11, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> -->


                  <li><a href="https://arxiv.org/abs/2208.12266" target="_blank"> <b> Decoding speech from non-invasive brain recordings </b> <br> </a> Alexandre Defossez, <b>Charlotte Caucheteux</b>, Jeremy Rapin, Ori Kabeli, Jean-Remi King.  <br> <font style="color:RGB(30,0,80);">  Forthcoming, <b> Nature Machine Intelligence </b>, 2022</font> </li> <p></p>
                  <li><a href="https://www.nature.com/articles/s41598-021-99991-6" target="_blank"> <b> Predictive usefulness of RT-PCR testing in different patterns of Covid-19 symptomatology: analysis of a French cohort of 12,810 outpatients. </b>
                    <br> </a> Caroline Apra*, <b>Charlotte Caucheteux*</b>, Arthur Mensch* et al.
                    , AP-HP/Universities/Inserm COVID-19 Research Collaboration.
<br> <font style="color:RGB(30,0,80);">  <b>Nature Scientific Reports</b>, 2021 </font> </li> <p></p>

                </ul>
                </p>

                <subheading>  <font size=3px> Conference Articles </font></subheading>
                <p>
                  <ul>


                    <li><a href="https://arxiv.org/abs/2206.01685" target="_blank"> <b> Toward a realistic model of speech processing in the brain with self-supervised learning </b> <br> </a> Juliette Millet*, <b>Charlotte Caucheteux*</b>, P. Orhan, Y. Boubenec, A. Gramfort, E. Dunbar, C. Pallier, J.R. King.  <br>
                      <font style="color:RGB(30,0,80);">   <b> NeurIPS </b>, 2022</font> </li> <p></p>

                    <!-- <font style="color:RGB(30,0,80);"> Findings of the Conference on Empirical Methods in Natural Language Processing <b> (EMLNP) </b>, 2021 </font> </li> <p></p> -->

                  <!-- <blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;Model-based analysis of brain activity reveals the hierarchy of language&quot;<br><br>Our EMNLP paper by <a href="https://twitter.com/c_caucheteux?ref_src=twsrc%5Etfw">@c_caucheteux</a> <a href="https://twitter.com/agramfort?ref_src=twsrc%5Etfw">@agramfort</a> &amp; myself is out: <a href="https://t.co/BxvrbZNkPt">https://t.co/BxvrbZNkPt</a><br><br>It shows (w/ emoji-based equations!) how deepnets can efficiently recover the language hierarchy in the<br><br>Summaryüëá<br>1/7 <a href="https://t.co/3QOcTfsivu">pic.twitter.com/3QOcTfsivu</a></p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1447909791435825159?ref_src=twsrc%5Etfw">October 12, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> -->

                  <li><a href="https://proceedings.mlr.press/v139/caucheteux21a.html" target="_blank"> <b> Disentangling syntax and semantics in the brain with deep networks </b> </a> <br> <b>Charlotte Caucheteux</b>, Alexandre Gramfort, Jean-Remi King.  <br>
                    <font style="color:RGB(30,0,80);"><b>ICML</b>, 2021</font> </li> <p></p>
                    <!-- <font style="color:RGB(30,0,80);">International Conference on Machine Learning <b>(ICML)</b>, 2021</font> </li> <p></p> -->

                    <li><a href="https://aclanthology.org/2021.findings-emnlp.308/" target="_blank"> <b> Model-based analysis of brain activity reveals the hierarchy of language in 305 subjects </b> <br> </a> <b>Charlotte Caucheteux</b>, Alexandre Gramfort, Jean-Remi King.  <br>
                      <font style="color:RGB(30,0,80);"> Findings of <b> EMLNP </b>, 2021 </font> </li> <p></p>
                    <!-- <blockquote class="twitter-tweet"><p lang="en" dir="ltr">Our new <a href="https://twitter.com/hashtag/ICML2021?src=hash&amp;ref_src=twsrc%5Etfw">#ICML2021</a> paper is out !<br><br>We align brain and GPT-2 activations to decompose the brain activity of 345 subjects into syntactic, semantic, lexical and compositional components. <br><br>Paper: <a href="https://t.co/fBbTHFSiAf">https://t.co/fBbTHFSiAf</a><br>Spotlight: <a href="https://t.co/hWOapyc2r5">https://t.co/hWOapyc2r5</a><br>Poster: Fri. 9am-11am CET <a href="https://t.co/17MwLP1K3j">https://t.co/17MwLP1K3j</a></p>&mdash; Charlotte Caucheteux (@c_caucheteux) <a href="https://twitter.com/c_caucheteux/status/1418305962662895621?ref_src=twsrc%5Etfw">July 22, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> -->

                    <!-- <font style="color:RGB(30,0,80);">  Neural Information Processing Systems <b> (NeurIPS) </b>, 2022</font> </li> <p></p> -->

                  <!-- <blockquote class="twitter-tweet"><p lang="en" dir="ltr">üî•Preprint out: <br><br>`Toward a realistic model of speech processing in the brain with self-supervised learning‚Äô:<a href="https://t.co/rJH6t6H6sm">https://t.co/rJH6t6H6sm</a><br><br>by J. Millet*, <a href="https://twitter.com/c_caucheteux?ref_src=twsrc%5Etfw">@c_caucheteux</a>* and our wonderful team:<br><br>The 3 main results summarized below üëá <a href="https://t.co/mdrJpbrb3M">pic.twitter.com/mdrJpbrb3M</a></p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1533720262344073218?ref_src=twsrc%5Etfw">June 6, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> -->


                  <!-- <blockquote class="twitter-tweet"><p lang="en" dir="ltr">Modern language algorithms are getting great but still remain far from humans.<br><br>To explain this gap, we hypothesize that the üß†, unlike these algorithms, is not tuned to predict adjacent words (i.e. a shorted-sighted goal) but rather makes long-range and hierarchical predictions. <a href="https://t.co/gujDxbMExl">pic.twitter.com/gujDxbMExl</a></p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1465716359246094342?ref_src=twsrc%5Etfw">November 30, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> -->




                  </ul>
              </p>

              <subheading>  <font size=3px> Press Coverage</font></subheading>
              <p>
                <ul>

                  <li><a href="https://ai.facebook.com/blog/studying-the-brain-to-build-ai-that-processes-language-as-people-do/" target="_blank">
                    <b> Studying the brain to build AI that processes language as people do. </b>
                  <br>
                </a> Meta AI blog post, April 2022.</li>
                <p></p>

                    <li><a href="https://ai.facebook.com/blog/ai-speech-brain-activity/" target="_blank"> <b> Using AI to decode speech from brain activity.
                    </b> </a>
                    <br>  Meta AI blog post, August 2022. </li>
                     <p></p>

                      <li><a href="https://time.com/6210261/meta-ai-brains-speech/" target="_blank"> <b> Meta Is Building AI That Reads Brainwaves. The Reality, So Far, Is Messy.
                      </b> </a>
                      <br> Time Magazine, September 2022. </li>
                      <p></p>



                      <!-- <li><a href="https://www.larecherche.fr/d%C3%A9crypter-les-r%C3%A9seaux-du-langage-dans-le-cerveau" target="_blank">
                        <b> Deciphering language networks in the brain.
                      </b> </a>
                      <br>
                        <br> <b> Universite Paris Saclay</b>, August 2022</font> </li> <p></p> -->


                      <li><a href="https://www.universite-paris-saclay.fr/actualites/le-langage-sera-t-il-decrypte-par-les-nouvelles-technologies" target="_blank">
                        <b> Will language be decrypted by new technologies?
                      </b> </a>  <br> La Recherche, December 2022. </li> <p></p>

                            </ul>
                </p>



                <ul>
 </li>
                </ul>
            </td>
          </tr>
        </tbody></table>

        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
        <heading> Selected Threads</heading>
        <p>
          <ul>

        </ul>
        </p>
      </td>
    </tr>
  </tbody></table> -->

  <table style="width:110%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
    <td style="padding:20px;width:110%;vertical-align:middle">
      <heading>Selected Threads  </heading>
      <br>
      <br>

      <blockquote class="twitter-tweet"><p lang="en" dir="ltr">Our paper is out in Nature Human Behaviourüî•üî•<br><br>‚ÄòEvidence of a predictive coding hierarchy in the human brain listening to speech‚Äô<br><br>üìÑ<a href="https://t.co/bkZ3AYMqDi">https://t.co/bkZ3AYMqDi</a><br>üí°Unlike language models, our brain makes distant &amp; hierarchical predictions<br><br>with <a href="https://twitter.com/agramfort?ref_src=twsrc%5Etfw">@agramfort</a> and <a href="https://twitter.com/JeanRemiKing?ref_src=twsrc%5Etfw">@JeanRemiKing</a><br><br>Threadüëá <a href="https://t.co/Jbs68EOaur">pic.twitter.com/Jbs68EOaur</a></p>&mdash; Charlotte Caucheteux (@c_caucheteux) <a href="https://twitter.com/c_caucheteux/status/1632740588352151556?ref_src=twsrc%5Etfw">March 6, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

      <blockquote class="twitter-tweet"><p lang="en" dir="ltr">üî•Our work has now been accepted to NeurIPS 2022 !! <br><br>`Toward a realistic model of speech processing in the brain with self-supervised learning‚Äô:<a href="https://t.co/weiGlaiD65">https://t.co/weiGlaiD65</a><br><br>Let‚Äôs meet in New Orleans on Tue 29 Nov 2:30pm PST (Hall J #524). <br><br>A recap of the 3 main results below üëá <a href="https://t.co/ng7w8luStr">pic.twitter.com/ng7w8luStr</a></p>&mdash; Charlotte Caucheteux @NeurIPS (@c_caucheteux) <a href="https://twitter.com/c_caucheteux/status/1592895883393499136?ref_src=twsrc%5Etfw">November 16, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

      <blockquote class="twitter-tweet"><p lang="en" dir="ltr">ü§ñüß† Our latest paper is now out:<a href="https://t.co/NZNea2VZ4U">https://t.co/NZNea2VZ4U</a><br><br>‚ÄúDeep language algorithms predict semantic comprehension from brain activity‚Äù, by <a href="https://twitter.com/c_caucheteux?ref_src=twsrc%5Etfw">@c_caucheteux</a>, <a href="https://twitter.com/agramfort?ref_src=twsrc%5Etfw">@agramfort</a> &amp; <a href="https://twitter.com/JeanRemiKing?ref_src=twsrc%5Etfw">@JeanRemiKing</a><br> <br>The summary thread below belowüëá<br><br>1/n <a href="https://t.co/CJfBdeDlY3">pic.twitter.com/CJfBdeDlY3</a></p>&mdash; Charlotte Caucheteux (@c_caucheteux) <a href="https://twitter.com/c_caucheteux/status/1579842525719732229?ref_src=twsrc%5Etfw">October 11, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


      <blockquote class="twitter-tweet"><p lang="en" dir="ltr">üéâPaper out: ‚ÄòBrains and algorithms partially converge in natural language processing‚Äô<br> <br>by <a href="https://twitter.com/c_caucheteux?ref_src=twsrc%5Etfw">@c_caucheteux</a>, and now freely available at Nature <a href="https://twitter.com/CommsBio?ref_src=twsrc%5Etfw">@CommsBio</a>:<a href="https://t.co/MpenOUaKwS">https://t.co/MpenOUaKwS</a><br> <br>The summary thread below üëá <a href="https://t.co/gMruZgGIOv">pic.twitter.com/gMruZgGIOv</a></p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1496425017474695169?ref_src=twsrc%5Etfw">February 23, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

      <blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;Model-based analysis of brain activity reveals the hierarchy of language&quot;<br><br>Our EMNLP paper by <a href="https://twitter.com/c_caucheteux?ref_src=twsrc%5Etfw">@c_caucheteux</a> <a href="https://twitter.com/agramfort?ref_src=twsrc%5Etfw">@agramfort</a> &amp; myself is out: <a href="https://t.co/BxvrbZNkPt">https://t.co/BxvrbZNkPt</a><br><br>It shows (w/ emoji-based equations!) how deepnets can efficiently recover the language hierarchy in the<br><br>Summaryüëá<br>1/7 <a href="https://t.co/3QOcTfsivu">pic.twitter.com/3QOcTfsivu</a></p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1447909791435825159?ref_src=twsrc%5Etfw">October 12, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

      <blockquote class="twitter-tweet"><p lang="en" dir="ltr">‚ÄòLong-range and hierarchical language predictions in brains and algorithms‚Äô<br> <br>Check-out our latest paper <a href="https://t.co/rwfVCVLRWA">https://t.co/rwfVCVLRWA</a> by <a href="https://twitter.com/c_caucheteux?ref_src=twsrc%5Etfw">@c_caucheteux</a> <a href="https://twitter.com/agramfort?ref_src=twsrc%5Etfw">@agramfort</a> <a href="https://twitter.com/jrking0?ref_src=twsrc%5Etfw">@jrking0</a><br> <br>tl;dr: Unlike deep language models, the brain makes long-range &amp; hierarchical predictions<br> <br>Thread belowüëá <a href="https://t.co/iP0BEYBjip">pic.twitter.com/iP0BEYBjip</a></p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1465716332264103940?ref_src=twsrc%5Etfw">November 30, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


      <ul>
</li>
        </ul>
    </td>
  </tr>
</tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Misc.</heading>
              <p>
                <ul>

                        <!-- <li> I received an MSc/BSc in Applied Mathematics from √âcole Polytechnique (<i>dipl√¥me d'Ing√©nieur</i>). During my studies, I was a Machine Learning intern at Owkin, BCG Gamma, and .</li><p></p> -->
                        <!-- <li> Outside of work, I enjoy playing soccer ‚öΩ &nbsp scuba diving üê† &nbsp and backpacking üåç   </li><p></p> -->
                        <li> I received an MSc/BSc from Ecole Polytechnique (<i>dipl√¥me d'Ing√©nieur</i>), with a specialisation in Machine Learning.<p></p>
                        <li> I have a strong interest in Healthcare. Prior to my PhD., I had the chance to work for Owkin, a start-up (now unicorn!) applying AI to oncology (2017). I also worked for the Assistance Publique‚ÄìH√¥pitaux de Paris (AP-HP) during the COVID crisis (2019).  </p>
                            <!-- <li> I also enjoy drawing actionable impact. Previous to my PhD., I had the chance to work for Owkin, a start-up using AI for oncology (2017), and for the Assistance Publique‚ÄìH√¥pitaux de Paris (AP-HP) during the COVID crisis (2019).  p></p> -->
                        <li> Finally, I enjoy arts arts üé® and music üéπ. In 2019, two teammates and I founded <a href="https://noartist.fr/" target="_blank"> NoArtist </a>, a collective of AI-generated artworks. We regularly organise exhibitions and events to democratise AI through arts.<p></p>

                </ul>
              </p>
            </td>
          </tr>
        </tbody></table>

        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <font style="color:RGB(200, 200, 200);">Website template from <a href="https://github.com/jonbarron/jonbarron_website" target="_blank"   style="color:RGB(200, 200, 200);">here</a></font>
              </p>
            </td>
          </tr>
        </tbody></table> -->


</body>

</html>
